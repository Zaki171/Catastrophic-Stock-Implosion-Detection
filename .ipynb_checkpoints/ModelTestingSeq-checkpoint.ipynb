{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b862fd7-75a8-4818-95c2-5375dde4b345",
   "metadata": {},
   "source": [
    "## Building the dataset that will be input into the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dda6c879-2ecc-475a-9f90-99bccea780bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SLF4J: Class path contains multiple SLF4J bindings.\n",
      "SLF4J: Found binding in [jar:file:/opt/hadoop-3.2.2/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: Found binding in [jar:file:/opt/apache-hive-2.3.7-bin/lib/log4j-slf4j-impl-2.6.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\n",
      "SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]\n",
      "2024-01-13 00:29:17,436 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "2024-01-13 00:29:20,107 WARN spark.ExecutorAllocationManager: Dynamic allocation without a shuffle service is an experimental feature.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "import pandas as pd\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf\n",
    "\n",
    "# for shared metastore (shared across all users)\n",
    "spark = SparkSession.builder.appName(\"Building dataset\").config(\"hive.metastore.uris\", \"thrift://amok:9083\", conf=SparkConf()).getOrCreate() \\\n",
    "\n",
    "# for local metastore (your private, invidivual database) add the following config to spark session\n",
    "spark.sql(\"USE 2023_11_02\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54391b05-47b8-4d4b-b943-eda194771996",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import pyspark.pandas as ps\n",
    "from pyspark.sql.functions import lit,col\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import xgboost as xgb\n",
    "#from boruta import BorutaPy\n",
    "#from fredapi import Fred\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import csv\n",
    "from pyspark.sql import functions as F\n",
    "from functools import reduce\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier, GBTClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder, CrossValidatorModel\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "from CreateDataset import get_features_all_stocks_seq, get_full_series_stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba39e2b3-07f5-4fd9-adf5-735d881bf565",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/spark/python/pyspark/sql/pandas/conversion.py:331: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():\n",
      "/opt/spark/python/pyspark/sql/pandas/conversion.py:331: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():\n",
      "2024-01-13 00:30:02,527 WARN scheduler.TaskSetManager: Stage 1 contains a task of very large size (2909 KiB). The maximum recommended task size is 1000 KiB.\n",
      "/opt/spark/python/pyspark/sql/pandas/conversion.py:331: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "233173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-13 00:30:11,560 WARN scheduler.TaskSetManager: Stage 7 contains a task of very large size (2909 KiB). The maximum recommended task size is 1000 KiB.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "233173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-13 00:30:17,596 WARN scheduler.TaskSetManager: Stage 12 contains a task of very large size (2909 KiB). The maximum recommended task size is 1000 KiB.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "233173\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'grouped_df_padded' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mImplosion_Start_Date\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mImplosion_Start_Date\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      5\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mImplosion_End_Date\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mImplosion_End_Date\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m----> 6\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mget_features_all_stocks_seq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_feats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#get stocks that have data in the ff_advanced_der_af for all years, not just prices (or not even)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#for boruta, maybe treat each column separately 22*10 features?\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#df.show()\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mcount())\n",
      "File \u001b[0;32m~/Stock-Implosion-Prediction-FYP/CreateDataset.py:277\u001b[0m, in \u001b[0;36mget_features_all_stocks_seq\u001b[0;34m(df, all_feats)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;66;03m#     grouped_df.show()\u001b[39;00m\n\u001b[1;32m    270\u001b[0m     \n\u001b[1;32m    271\u001b[0m     \u001b[38;5;66;03m#PADDING VALUES WITH 0S\u001b[39;00m\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;66;03m# grouped_df_padded = grouped_df.select(\"fsym_id\",\u001b[39;00m\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;66;03m#     *[F.expr(f\"IF(size({col}) < 22, concat({col}, array_repeat(0.0, 22 - size({col}))), {col})\").alias(col) for col \u001b[39;00m\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;66;03m#       in feature_cols])\u001b[39;00m\n\u001b[1;32m    276\u001b[0m     orig_df \u001b[38;5;241m=\u001b[39m orig_df\u001b[38;5;241m.\u001b[39mwithColumn(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m, F\u001b[38;5;241m.\u001b[39mwhen(F\u001b[38;5;241m.\u001b[39misnull(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mImplosion_Start_Date\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39motherwise(\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m--> 277\u001b[0m     joined_df \u001b[38;5;241m=\u001b[39m \u001b[43mgrouped_df_padded\u001b[49m\u001b[38;5;241m.\u001b[39mjoin(orig_df\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfsym_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfsym_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minner\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    278\u001b[0m     joined_df\u001b[38;5;241m=\u001b[39mjoined_df\u001b[38;5;241m.\u001b[39morderBy(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfsym_id\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m joined_df\n",
      "\u001b[0;31mNameError\u001b[0m: name 'grouped_df_padded' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('imploded_stocks_price.csv', index_col=False)\n",
    "#full_series_stocks = get_full_series_stocks(df) #this gets the stocks that have data since 2001\n",
    "#filtered_df = df[df['fsym_id'].isin(full_series_stocks)]\n",
    "df['Implosion_Start_Date'] = pd.to_datetime(df['Implosion_Start_Date'])\n",
    "df['Implosion_End_Date'] = pd.to_datetime(df['Implosion_End_Date'])\n",
    "df = get_features_all_stocks_seq(df, all_feats=False) #get stocks that have data in the ff_advanced_der_af for all years, not just prices (or not even)\n",
    "#for boruta, maybe treat each column separately 22*10 features?\n",
    "#df.show()\n",
    "print(df.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a2e0bd-1dac-455b-bca0-485707f1f52c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark.sql(\"SELECT fsym_id, date FROM FF_ADVANCED_DER_AF WHERE fsym_id = 'B01DPB-R'\").show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30d429c-7d3d-4325-bc80-2471074b13ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(df.filter(df['label'] == 1).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e7c04c-6dc4-4ac2-a544-5e3c187cfaaf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63645eaf-dfa5-43d5-ab36-e94c6ced8c79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def train_test_split(df):\n",
    "    train, test = df.randomSplit([0.7,0.3])\n",
    "    return train, test\n",
    "\n",
    "\n",
    "def confusion_matrix_pandas(df):\n",
    "    df = df.toPandas()\n",
    "    cm = confusion_matrix(df['label'], df['prediction'])\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Predicted 0', 'Predicted 1'], yticklabels=['Actual 0', 'Actual 1'])\n",
    "    plt.title(f'Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def model_testing(df):\n",
    "    df = df.filter(reduce(lambda acc, column: acc & (F.size(col(column)) == 22), df.columns[1:-1], lit(True)))\n",
    "\n",
    "    #need to decide whether to only include stocks that started from 2000, or include just from e.g. 2019\n",
    "    #temporary measure - replace with 0\n",
    "    #try imputer?\n",
    "    #look into masking\n",
    "    \n",
    "    print(\"Number of records: \", df.count())\n",
    "    features = df.columns[1:-1]\n",
    "    list_to_vector_udf = udf(lambda l: Vectors.dense(l), VectorUDT())\n",
    "    for f in features:\n",
    "        df = df.withColumn(f, list_to_vector_udf(f))\n",
    "    df.show(2)\n",
    "    train_df, test_df = train_test_split(df)\n",
    "    \n",
    "    vector_assembler = VectorAssembler(inputCols=features, outputCol=\"features_vector\")\n",
    "    train_df = vector_assembler.transform(train_df)\n",
    "    test_df = vector_assembler.transform(test_df)\n",
    "    \n",
    "    lr = LogisticRegression(featuresCol=\"features_vector\", labelCol=\"label\")\n",
    "    rf = RandomForestClassifier(featuresCol='features_vector', labelCol='label')\n",
    "    gbt = GBTClassifier(featuresCol = 'features_vector', labelCol='label')\n",
    "    models = [rf]\n",
    "    model_names = ['random forest']\n",
    "    \n",
    "    for model, model_name in zip(models, model_names):\n",
    "        if model_name == 'random forest':\n",
    "            paramGrid = ParamGridBuilder() \\\n",
    "                .addGrid(model.numTrees, [100]) \\\n",
    "                .addGrid(model.maxDepth, [15]) \\\n",
    "                .addGrid(model.minInstancesPerNode, [5]) \\\n",
    "                .build()\n",
    "        elif model_name == 'logistic regression':\n",
    "            paramGrid = ParamGridBuilder() \\\n",
    "                .addGrid(lr.regParam, [0.1]) \\\n",
    "                .addGrid(lr.elasticNetParam, [0.5]) \\\n",
    "                .addGrid(lr.maxIter, [100]) \\\n",
    "                .build()\n",
    "        else:\n",
    "            paramGrid = ParamGridBuilder() \\\n",
    "                .addGrid(gbt.maxDepth, [10]) \\\n",
    "                .addGrid(gbt.maxBins, [32]) \\\n",
    "                .addGrid(gbt.maxIter, [20]) \\\n",
    "                .build()\n",
    "\n",
    "        evaluator = BinaryClassificationEvaluator(labelCol=\"label\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n",
    "\n",
    "        crossval = CrossValidator(estimator=model,\n",
    "                                  estimatorParamMaps=paramGrid,\n",
    "                                  evaluator=evaluator,\n",
    "                                  numFolds=5, parallelism=12)\n",
    "\n",
    "        cvModel = crossval.fit(train_df)\n",
    "\n",
    "        avg_metrics = cvModel.avgMetrics\n",
    "        print(model_name.upper())\n",
    "\n",
    "        for i, acc in enumerate(avg_metrics):\n",
    "            print(f\"Fold {i + 1} - Validation Accuracy: {acc}\")\n",
    "\n",
    "        best_model = cvModel.bestModel\n",
    "\n",
    "        predictions = best_model.transform(test_df)\n",
    "\n",
    "        confusion_matrix_pandas(predictions.select('label', 'prediction'))\n",
    "        \n",
    "def basic_test(df):\n",
    "    df = df.filter(reduce(lambda acc, column: acc & (F.size(col(column)) == 22), df.columns[1:-1], lit(True)))\n",
    "    print(\"Number of records: \", df.count())\n",
    "    features = df.columns[1:-1]\n",
    "    list_to_vector_udf = udf(lambda l: Vectors.dense(l), VectorUDT())\n",
    "    for f in features:\n",
    "        df = df.withColumn(f, list_to_vector_udf(f))\n",
    "    df.show(2)\n",
    "    train_df, test_df = train_test_split(df)\n",
    "    \n",
    "    vector_assembler = VectorAssembler(inputCols=features, outputCol=\"features_vector\")\n",
    "    train_df = vector_assembler.transform(train_df)\n",
    "    test_df = vector_assembler.transform(test_df)\n",
    "    \n",
    "    lr = LogisticRegression(featuresCol=\"features_vector\", labelCol=\"label\")\n",
    "    rf = RandomForestClassifier(featuresCol='features_vector', labelCol='label')\n",
    "    gbt = GBTClassifier(featuresCol = 'features_vector', labelCol='label')\n",
    "    models = [lr, rf, gbt]\n",
    "    model_names = ['logistic regression']\n",
    "    \n",
    "    for model, model_name in zip(models, model_names):\n",
    "        if model_name == 'boosted trees':\n",
    "            paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(gbt.maxDepth, [10])\n",
    "             .addGrid(gbt.maxIter, [50])\n",
    "             .build())\n",
    "        elif model_name == 'random forest':\n",
    "            paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(rf.maxDepth, [5]) #5,10,15\n",
    "             .addGrid(rf.numTrees, [20]) #20,50,100\n",
    "             .build())\n",
    "        else:\n",
    "            paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(lr.maxIter, [10])  # Number of iterations #10,50,100\n",
    "             .addGrid(lr.regParam, [0.01])  # Regularization parameter #0.01,0.1,0.5\n",
    "             .addGrid(lr.elasticNetParam, [0.0])  # Elastic net parameter (0 for L2, 1 for L1) 0.0,0.5,1.0\n",
    "             .build())\n",
    "    \n",
    "\n",
    "\n",
    "        evaluator = BinaryClassificationEvaluator(labelCol=\"label\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n",
    "        \n",
    "        crossval = CrossValidator(estimator = model, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=5)\n",
    "        \n",
    "        model = crossval.fit(train_df)\n",
    "        \n",
    "        best_model = model.bestModel\n",
    "\n",
    "        print(model_name.upper())\n",
    "\n",
    "        predictions = best_model.transform(test_df)\n",
    "\n",
    "        confusion_matrix_pandas(predictions.select('label', 'prediction'))\n",
    "        \n",
    "        recall = evaluator.evaluate(predictions)\n",
    "        print(f\"Recall: {recall}\")\n",
    "    \n",
    "\n",
    "\n",
    "#basic_test(df)\n",
    "#test_pandas(df)\n",
    "#model_testing(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb392cd-c08f-4884-bf9d-80ef508a15ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, hp\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "import csv\n",
    "    \n",
    "def model_training(df, classifier):\n",
    "    df = df.filter(reduce(lambda acc, column: acc & (F.size(col(column)) == 22), df.columns[1:-1], lit(True)))\n",
    "    print(\"Number of records: \", df.count())\n",
    "    \n",
    "    features = df.columns[1:-1]\n",
    "\n",
    "    list_to_vector_udf = F.udf(lambda l: Vectors.dense(l), VectorUDT())\n",
    "    for f in features:\n",
    "        df = df.withColumn(f, list_to_vector_udf(f))\n",
    " \n",
    "    train_df, test_df = train_test_split(df)\n",
    "\n",
    "    vector_assembler = VectorAssembler(inputCols=features, outputCol=\"features_vector\")\n",
    "    train_df = vector_assembler.transform(train_df)\n",
    "    test_df = vector_assembler.transform(test_df)\n",
    "\n",
    "    if classifier == 'LogisticRegression':\n",
    "        param_space = {\n",
    "            'regParam': hp.uniform('regParam', 0.01, 1.0),\n",
    "            'elasticNetParam': hp.uniform('elasticNetParam', 0.0, 1.0)\n",
    "        }\n",
    "        classifier_instance = LogisticRegression(featuresCol=\"features_vector\", labelCol=\"label\")\n",
    "    elif classifier == 'RandomForest':\n",
    "        param_space = {\n",
    "            'maxBins': hp.quniform('maxBins', 16, 32, 1),\n",
    "            'maxDepth': hp.quniform('maxDepth', 20, 30, 1)\n",
    "        }\n",
    "        classifier_instance = RandomForestClassifier(featuresCol='features_vector', labelCol='label')\n",
    "    elif classifier == 'GBT':\n",
    "        param_space = {\n",
    "            'maxDepth' : hp.quniform(\"maxDepth\", 3, 18, 1),\n",
    "            'maxBins': hp.quniform('maxBins', 16, 32, 1)\n",
    "        }\n",
    "        classifier_instance = GBTClassifier(featuresCol='features_vector', labelCol='label')\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported classifier\")\n",
    "    \n",
    "    initial_model = classifier_instance\n",
    "    initial_model = initial_model.fit(train_df)\n",
    "\n",
    "    def cross_val_train(params):\n",
    "        classifier_instance.setParams(**params)\n",
    "        #evaluator = BinaryClassificationEvaluator(metricName='areaUnderPR')\n",
    "        evaluator = MulticlassClassificationEvaluator(predictionCol='prediction', metricName='f1')\n",
    "        train, val = train_df.randomSplit([0.9,0.1])\n",
    "        curr_model = classifier_instance.fit(train)\n",
    "        predictions = curr_model.transform(val)\n",
    "        val_metric = evaluator.evaluate(predictions)\n",
    "        return curr_model, val_metric\n",
    "#         crossval = CrossValidator(estimator=classifier_instance,\n",
    "#                                   estimatorParamMaps=[params],\n",
    "#                                   evaluator=evaluator,\n",
    "#                                   numFolds=5, parallelism=12)\n",
    "        \n",
    "#         cv_model = crossval.fit(train_df)\n",
    "#         predictions = cv_model.transform(train_df)\n",
    "#         val_metric = evaluator.evaluate(predictions)\n",
    "#         return cv_model, val_metric\n",
    "    \n",
    "    \n",
    "    def objective(params):\n",
    "        model, metric = cross_val_train(params)\n",
    "        return -metric\n",
    "\n",
    "    # Find the best hyperparameters\n",
    "    best_params = fmin(fn=objective, space=param_space, algo=tpe.suggest, max_evals=5)\n",
    "    print(\"Best hyperparameters: \", best_params)\n",
    "\n",
    "    # Train the model with the best hyperparameters\n",
    "    best_model, final_metric = cross_val_train(best_params)\n",
    "    if classifier!='LogisticRegression':\n",
    "        feature_importances = best_model.featureImportances\n",
    "        print(\"Feature Importances:\")\n",
    "        for i in range(len(feature_importances)):\n",
    "            print(\"Feature {}: {}\".format(i, feature_importances[i]))\n",
    "            \n",
    "    \n",
    "    predictions = best_model.transform(test_df)\n",
    "    final_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n",
    "    report = {\n",
    "        'accuracy': final_evaluator.evaluate(predictions, {final_evaluator.metricName: \"accuracy\"}),\n",
    "        'f1': final_evaluator.evaluate(predictions, {final_evaluator.metricName: \"f1\"}),\n",
    "        'weightedPrecision': final_evaluator.evaluate(predictions, {final_evaluator.metricName: \"weightedPrecision\"}),\n",
    "        'weightedRecall': final_evaluator.evaluate(predictions, {final_evaluator.metricName: \"weightedRecall\"}),\n",
    "        'precisionByLabel': final_evaluator.evaluate(predictions, {final_evaluator.metricName: \"precisionByLabel\"}),\n",
    "        'recallByLabel': final_evaluator.evaluate(predictions, {final_evaluator.metricName: \"recallByLabel\"}),\n",
    "        'logLoss': final_evaluator.evaluate(predictions, {final_evaluator.metricName: \"logLoss\"}),\n",
    "        'hammingLoss': final_evaluator.evaluate(predictions, {final_evaluator.metricName: \"hammingLoss\"})\n",
    "    }\n",
    "    initial_model_test_metric = final_evaluator.evaluate(initial_model.transform(test_df), {final_evaluator.metricName: \"f1\"})\n",
    "    print(\"Initial Model F1: \", initial_model_test_metric)\n",
    "    print(report)\n",
    "    fp = f'{classifier}_seq.csv'\n",
    "    with open(fp, 'w', newline='') as csv_file:\n",
    "        csv_writer = csv.writer(csv_file)\n",
    "        csv_writer.writerow(report.keys())\n",
    "        csv_writer.writerow(report.values())\n",
    "\n",
    "    confusion_matrix_pandas(predictions.select('label', 'prediction'))\n",
    "    \n",
    "    \n",
    "    \n",
    "# model_training(df, 'LogisticRegression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132d4208-33fb-495c-80e4-7fd539457c2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_seqs(df, all_feats=False):\n",
    "    orig_df = spark.createDataFrame(df)\n",
    "    table = \"FF_ADVANCED_DER_AF\"\n",
    "    def generate_dates():\n",
    "        start_date = datetime(2001, 1, 1)\n",
    "        end_date = datetime(2022, 12, 31)\n",
    "        current_date = start_date\n",
    "\n",
    "        while current_date <= end_date:\n",
    "            yield current_date\n",
    "            current_date += pd.DateOffset(years=1) #generating placeholder dates\n",
    "    \n",
    "    df['date_for_year'] = df['fsym_id'].map({k: list(generate_dates()) for k, g in df.groupby('fsym_id')})\n",
    "    df=df.explode('date_for_year')\n",
    "    df['date_for_year']= pd.to_datetime(df['date_for_year'])\n",
    "    df['year'] = df['date_for_year'].dt.year\n",
    "    \n",
    "    \n",
    "    spark_df = spark.createDataFrame(df)\n",
    "    spark_df.createOrReplaceTempView(\"temp_table\")\n",
    "    if all_feats:\n",
    "        col_names = get_not_null_cols(df)\n",
    "    else:\n",
    "        col_names = get_feature_col_names()\n",
    "    col_string = ', '.join('a.' + item for item in col_names)\n",
    "    q=f\"\"\"SELECT t.fsym_id, t.year, a.date, {col_string}\n",
    "                FROM temp_table t\n",
    "                LEFT JOIN {table} a ON t.fsym_id = a.fsym_id AND t.year = YEAR(a.date)\n",
    "                LEFT JOIN FF_BASIC_AF b ON b.fsym_id = t.fsym_id and t.year = YEAR(b.date)\n",
    "                ORDER BY t.fsym_id, t.year\"\"\"\n",
    "\n",
    "    \n",
    "    features_df = spark.sql(q)\n",
    "    features_df = features_df.withColumn(\"non_null_2001\", F.when((F.col(\"year\") == 2001) & (F.col(\"date\").isNotNull()), 1).otherwise(0))\n",
    "    \n",
    "    ws = Window.partitionBy(\"fsym_id\")\n",
    "\n",
    "    features_df = features_df.withColumn(\"group_non_null_2001\", F.sum(\"non_null_2001\").over(ws))\n",
    "\n",
    "    features_df = features_df.filter((F.col(\"group_non_null_2001\") > 0))\n",
    "\n",
    "    features_df = features_df.drop(\"non_null_2001\", \"group_non_null_2001\")\n",
    "    feature_cols = [column for column in features_df.columns if column not in ['fsym_id', 'date', 'year']]\n",
    "    sequences = []\n",
    "    \n",
    "    #PADDING WITH 0s\n",
    "    # grouped_df_padded = grouped_df.select(\"fsym_id\",\n",
    "    #     *[F.expr(f\"IF(size({col}) < 23, concat({col}, array_repeat(0, 23 - size({col}))), {col})\").alias(col) for col \n",
    "    #       in feature_cols])\n",
    "    \n",
    "    #forward filling\n",
    "    window_spec = Window.partitionBy('fsym_id').orderBy('year')\n",
    "    for c in feature_cols:\n",
    "        features_df = features_df.withColumn(\n",
    "            c, F.last(c, ignorenulls=True).over(window_spec)\n",
    "        )\n",
    "        \n",
    "    # features_df.orderBy('fsym_id','year').show(200)\n",
    "    # null_counts_per_year = features_df.groupBy(\"year\").agg(\n",
    "    #     *[F.sum(F.when(F.col(column).isNull(), 1).otherwise(0)).alias(f\"{column}_null_count\") for column in feature_cols]\n",
    "    # )\n",
    "    # null_counts_per_year.orderBy('year').show(100)\n",
    "    # features_df.orderBy('year', 'fsym_id').show(100)\n",
    "    \n",
    "    #SCALING- should move\n",
    "    window_spec2 = Window.partitionBy('year').orderBy('year')\n",
    "    for c in feature_cols:\n",
    "        features_df = features_df.withColumn(c, ((F.col(c) - F.mean(F.col(c)).over(window_spec2)) /\n",
    "                                            F.stddev(F.col(c)).over(window_spec2)))\n",
    "\n",
    "    grouped_df = features_df.groupBy(\"fsym_id\").agg(\n",
    "        *[F.collect_list(col).alias(col) for col in feature_cols]) #creating lists per cell\n",
    "    \n",
    "    #PADDING VALUES WITH 0S\n",
    "    grouped_df_padded = grouped_df.select(\"fsym_id\",\n",
    "        *[F.expr(f\"IF(size({col}) < 22, concat({col}, array_repeat(0.0, 22 - size({col}))), {col})\").alias(col) for col \n",
    "          in feature_cols])\n",
    "    \n",
    "    orig_df = orig_df.withColumn('label', F.when(F.isnull('Implosion_Start_Date'), 0).otherwise(1))\n",
    "    joined_df = grouped_df_padded.join(orig_df.select(\"fsym_id\", \"label\"), \"fsym_id\", \"inner\")\n",
    "    joined_df=joined_df.orderBy('fsym_id')\n",
    "\n",
    "    \n",
    "    return joined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8882a899-98b5-4b95-ba1c-5de2a137a0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def nn_prepare_seqs(df):\n",
    "    df = df.filter(reduce(lambda acc, column: acc & (F.size(col(column)) == 22), df.columns[1:-1], F.lit(True)))\n",
    "    print(\"Number of records: \", df.count())\n",
    "    features = df.columns[1:-1]\n",
    "    list_to_vector_udf = udf(lambda l: Vectors.dense(l), VectorUDT())\n",
    "    for f in features:\n",
    "        df = df.withColumn(f, list_to_vector_udf(f))\n",
    "    train_df, test_df = train_test_split(df)\n",
    "    train_df = train_df.toPandas()\n",
    "    test_df = test_df.toPandas()\n",
    "    \n",
    "    train_seqs = []\n",
    "    for stock_id, group in train_df.groupby('fsym_id'):\n",
    "        seq_feats = group[features]\n",
    "        label = group['label']\n",
    "        feat_length = len(seq_feats.iloc[0])\n",
    "        date_length = len(seq_feats.iloc[0,0])\n",
    "        seq_array = np.zeros((feat_length, date_length))\n",
    "        for i, sublist in enumerate(seq_feats.columns):\n",
    "            seq_array[i, :] = np.array(seq_feats[sublist].iloc[0])\n",
    "        seq_array = seq_array.T\n",
    "        train_seqs.append((seq_array, label))\n",
    "        \n",
    "    test_seqs = []\n",
    "    for stock_id, group in test_df.groupby('fsym_id'):\n",
    "        seq_feats = group[features]\n",
    "        label = group['label']\n",
    "        feat_length = len(seq_feats.iloc[0])\n",
    "        date_length = len(seq_feats.iloc[0,0])\n",
    "        seq_array = np.zeros((feat_length, date_length))\n",
    "        for i, sublist in enumerate(seq_feats.columns):\n",
    "            seq_array[i, :] = np.array(seq_feats[sublist].iloc[0])\n",
    "        seq_array = seq_array.T\n",
    "        test_seqs.append((seq_array, label))\n",
    "    \n",
    "    return train_seqs, test_seqs\n",
    "\n",
    "def nn_training(train_seqs, test_seqs):\n",
    "    train_X, train_y = zip(*train_seqs)\n",
    "    test_X, test_y = zip(*test_seqs)\n",
    "\n",
    "    # Convert lists to numpy arrays\n",
    "    train_X = np.array(train_X)\n",
    "    train_y = np.array(train_y)\n",
    "    test_X = np.array(test_X)\n",
    "    test_y = np.array(test_y)\n",
    "\n",
    "    # Define the neural network model\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(train_X.shape[1], train_X.shape[2])),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(train_X, train_y, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    test_loss, test_acc = model.evaluate(test_X, test_y)\n",
    "    print(f'Test accuracy: {test_acc}')\n",
    "\n",
    "    # Make predictions on new data\n",
    "    predictions = model.predict(test_X)\n",
    "    for i in range(len(predictions)):\n",
    "        predictions[i] = 1 if predictions[i] >= 0.5 else 0\n",
    "    print(predictions)\n",
    "    \n",
    "    # pred_df = pd.DataFrame()\n",
    "    # pred_df['prediction'] = predictions\n",
    "    # pred_df['label'] = test_y\n",
    "    # confusion_matrix_pandas(pred_df)\n",
    "    cm = confusion_matrix(test_y, predictions)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Predicted 0', 'Predicted 1'], yticklabels=['Actual 0', 'Actual 1'])\n",
    "    plt.title(f'Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.show()\n",
    "\n",
    "train_seqs, test_seqs = nn_prepare_seqs(df)\n",
    "nn_training(train_seqs, test_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70d2c79-f857-4688-84be-7965097c3047",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from tqdm.auto import tqdm\n",
    "\n",
    "# import torch\n",
    "# import torch.autograd as autograd\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "# import torch.optim as optim\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# import seaborn as sns\n",
    "# from pylab import rcParams\n",
    "# import matplotlib.pyplot as plt\n",
    "# from matplotlib import rc\n",
    "# import matplotlib\n",
    "# from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "# from sklearn.metrics import classification_report, confusion_matrix\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# from multiprocessing import cpu_count\n",
    "\n",
    "\n",
    "\n",
    "# class SequenceModel(nn.Module):\n",
    "#     def __init__(self, n_features, n_classes, n_hidden=256, n_layers=3):\n",
    "#         super().__init__()\n",
    "\n",
    "#         self.lstm = nn.LSTM(\n",
    "#             input_size = n_features,\n",
    "#             hidden_size = n_hidden,\n",
    "#             batch_first = True,\n",
    "#             num_layers = n_layers, # Stack LSTMs\n",
    "#             dropout = 0.2  # This model works on a lot of regularisation\n",
    "#         )\n",
    "\n",
    "#         self.classifier = nn.Linear(n_hidden, n_classes)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         self.lstm.flatten_parameters()  # For distrubuted training\n",
    "\n",
    "#         _, (hidden, _) = self.lstm(x)\n",
    "#         # We want the output from the last layer to go into the final\n",
    "#         # regressor linear layer\n",
    "#         out = hidden[-1] \n",
    "\n",
    "#         return self.classifier(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b910d24-3885-4d00-857b-90ca055539c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK\n",
    "\n",
    "def train_tree(train_df):\n",
    "    rf = RandomForestClassifier(featuresCol='features_vector', labelCol='label', maxDepth=maxDepth, numTrees=numTrees)\n",
    "    model = rf.fit(train_df)\n",
    "    preds = model.transform()\n",
    "    \n",
    "\n",
    "            \n",
    "    \n",
    "    \n",
    "\n",
    "def train_with_hyperopt(params, df):\n",
    "    numTrees = int(params['numTrees'])\n",
    "    maxDepth = int(params['maxDepth'])\n",
    "\n",
    "    model, f1_score = train_rf(numTrees, maxDepth, df)\n",
    "    loss = - f1_score\n",
    "    return {'loss': loss, 'status': STATUS_OK}\n",
    "\n",
    "def prepare_df():\n",
    "    df = df.filter(reduce(lambda acc, column: acc & (F.size(col(column)) == 22), df.columns[1:-1], lit(True)))\n",
    "    print(\"Number of records: \", df.count())\n",
    "    features = df.columns[1:-1]\n",
    "    list_to_vector_udf = udf(lambda l: Vectors.dense(l), VectorUDT())\n",
    "    for f in features:\n",
    "        df = df.withColumn(f, list_to_vector_udf(f))\n",
    "    df.show(2)\n",
    "    train_df, test_df = train_test_split(df)\n",
    "    \n",
    "    vector_assembler = VectorAssembler(inputCols=features, outputCol=\"features_vector\")\n",
    "    train_df = vector_assembler.transform(train_df)\n",
    "    test_df = vector_assembler.transform(test_df)\n",
    "    return train_df, test_df\n",
    "\n",
    "# train_df, test_df = prepare_df(df)\n",
    "# train_with_hyperopt()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f034c3-4ed9-400e-a07b-6d2c6be018d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(filtered_df.filter(F.col('label')==1).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8b9373-fceb-4cf1-9c66-aab50d165c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.filter(F.col('label')==1).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1698c017-00e4-4208-8305-518dd1746e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c12702-06f6-442b-9787-3d03ef354eec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
