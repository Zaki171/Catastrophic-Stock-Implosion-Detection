{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b862fd7-75a8-4818-95c2-5375dde4b345",
   "metadata": {},
   "source": [
    "## Building the dataset that will be input into the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc9cedb4-51ae-42f3-8064-60ce28dd207c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "import pandas as pd\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf\n",
    "\n",
    "# for shared metastore (shared across all users)\n",
    "spark = SparkSession.builder.appName(\"Building dataset\").config(\"hive.metastore.uris\", \"thrift://bialobog:9083\", conf=SparkConf()).getOrCreate() \\\n",
    "\n",
    "# for local metastore (your private, invidivual database) add the following config to spark session\n",
    "spark.sql(\"USE 2023_04_01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63645eaf-dfa5-43d5-ab36-e94c6ced8c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imploded query done\n",
      "got non imploded stocks\n",
      "non imploded query done\n",
      "    Ticker       date  FF_PRICE_CLOSE_FP  ff_debt_entrpr_val  \\\n",
      "0     A-US 2022-10-31          138.35001            0.067346   \n",
      "1    AA-US 2022-12-31           45.47000            0.189013   \n",
      "2  AAAP-US 2016-12-31           26.76000            0.019984   \n",
      "3   AAB-US 1998-12-31           20.68800            0.003673   \n",
      "4  AABC-US 2004-12-31           14.51000            0.550329   \n",
      "\n",
      "   ff_tot_debt_tcap_std  ff_fix_assets_com_eq  ff_debt_eq  ff_debt_com_eq  \\\n",
      "0             35.509361             23.562677   55.061263       55.061263   \n",
      "1             27.194492            127.915682   37.352246       37.352246   \n",
      "2              5.167838             21.343347    5.449458        5.449458   \n",
      "3              1.672403             37.411357    1.700848        1.700848   \n",
      "4             41.452296             39.513874   70.800875       70.800875   \n",
      "\n",
      "   ff_inven_curr_assets  ff_ltd_com_eq  ...  ff_fcf_yld  ff_mkt_val_gr  \\\n",
      "0             27.474854      53.421301  ...     1.85761      -14.17310   \n",
      "1             46.228571      36.741529  ...     3.28065      -26.63840   \n",
      "2              3.010615       4.108047  ...    -1.66472       -4.18651   \n",
      "3             14.325069       0.193237  ...     3.52222       25.38180   \n",
      "4                   NaN      53.088754  ...    -5.32875       33.08130   \n",
      "\n",
      "   ff_earn_yld  ff_pbk_tang  ff_zscore  ff_entrpr_val_sales  ff_psales_dil  \\\n",
      "0      3.02132     76.78400    6.09575             6.333670       6.060890   \n",
      "1     -1.49461      1.64153    1.96326             0.786011       0.644889   \n",
      "2     -2.55717      5.06308    6.30104             7.137950       8.936470   \n",
      "3          NaN      1.28681    3.41281             4.361930       4.731780   \n",
      "4      5.37560      2.38754        NaN             1.567230       1.226230   \n",
      "\n",
      "   Implosion_Next_Year       CPI  Unemployment Rate  \n",
      "0                    0  0.004883                3.7  \n",
      "1                    0  0.001313                3.5  \n",
      "2                    0  0.002525                4.7  \n",
      "3                    0  0.001828                4.4  \n",
      "4                    0  0.000000                5.4  \n",
      "\n",
      "[5 rows x 26 columns]\n",
      "dropped cols:  []\n",
      "before dropping nulls:  11354\n",
      "after dropping nulls:  3620\n",
      "number of implosions:  397\n",
      "number of non-implosions:  3223\n",
      "dataset written\n",
      "   FF_PRICE_CLOSE_FP  ff_debt_entrpr_val  ff_tot_debt_tcap_std  \\\n",
      "0          138.35001            0.067346             35.509361   \n",
      "1           45.47000            0.189013             27.194492   \n",
      "2           26.76000            0.019984              5.167838   \n",
      "3           25.50000            0.000000              0.000000   \n",
      "4            1.89000            0.901241             45.716587   \n",
      "\n",
      "   ff_fix_assets_com_eq  ff_debt_eq  ff_debt_com_eq  ff_inven_curr_assets  \\\n",
      "0             23.562677   55.061263       55.061263             27.474854   \n",
      "1            127.915682   37.352246       37.352246             46.228571   \n",
      "2             21.343347    5.449458        5.449458              3.010615   \n",
      "3              0.167811    0.000000        0.000000              0.000000   \n",
      "4            116.844100   84.218335       84.218335             43.501452   \n",
      "\n",
      "   ff_ltd_com_eq  ff_liabs_lease  ff_ltd_tcap  ...  ff_earn_yld  ff_pbk_tang  \\\n",
      "0      53.421301      101.000000    34.451738  ...      3.02132    76.784000   \n",
      "1      36.741529       59.000000    26.749857  ...     -1.49461     1.641530   \n",
      "2       4.108047        3.538686     3.895750  ...     -2.55717     5.063080   \n",
      "3       0.000000        0.000000     0.000000  ...    -18.02430     1.176130   \n",
      "4      46.034007        5.505000    24.988830  ...   -126.15900     0.298919   \n",
      "\n",
      "   ff_zscore  ff_entrpr_val_sales  ff_psales_dil       CPI  Unemployment Rate  \\\n",
      "0   6.095750             6.333670       6.060890  0.004883                3.7   \n",
      "1   1.963260             0.786011       0.644889  0.001313                3.5   \n",
      "2   6.301040             7.137950       8.936470  0.002525                4.7   \n",
      "3   5.823320            -0.244653       2.861600  0.000685                3.9   \n",
      "4  -0.372384             0.774483       0.236200  0.001313                3.5   \n",
      "\n",
      "   Year  Month  DayOfWeek  \n",
      "0  2022     10          0  \n",
      "1  2022     12          5  \n",
      "2  2016     12          5  \n",
      "3  2018     12          0  \n",
      "4  2022     12          5  \n",
      "\n",
      "[5 rows x 26 columns]\n",
      "Feature Importances for Fold 5:\n",
      "                 Feature  Importance\n",
      "12      ff_oper_inc_tcap   -0.102182\n",
      "21                   CPI    0.063138\n",
      "18             ff_zscore    0.044068\n",
      "15         ff_mkt_val_gr    0.042563\n",
      "22     Unemployment Rate    0.039214\n",
      "13          ff_assets_gr    0.035814\n",
      "23                  Year    0.032801\n",
      "16           ff_earn_yld   -0.026059\n",
      "0      FF_PRICE_CLOSE_FP    0.023251\n",
      "24                 Month    0.018247\n",
      "6   ff_inven_curr_assets   -0.015300\n",
      "11             ff_bps_gr   -0.012943\n",
      "25             DayOfWeek   -0.005807\n",
      "20         ff_psales_dil   -0.003200\n",
      "8         ff_liabs_lease   -0.002201\n",
      "19   ff_entrpr_val_sales   -0.000000\n",
      "2   ff_tot_debt_tcap_std   -0.000000\n",
      "3   ff_fix_assets_com_eq   -0.000000\n",
      "4             ff_debt_eq    0.000000\n",
      "9            ff_ltd_tcap   -0.000000\n",
      "5         ff_debt_com_eq    0.000000\n",
      "10        ff_sales_wkcap   -0.000000\n",
      "7          ff_ltd_com_eq    0.000000\n",
      "14            ff_fcf_yld   -0.000000\n",
      "1     ff_debt_entrpr_val   -0.000000\n",
      "17           ff_pbk_tang    0.000000\n",
      "Feature Importances for Fold 5:\n",
      "                 Feature  Importance\n",
      "12      ff_oper_inc_tcap   -0.091614\n",
      "21                   CPI    0.052138\n",
      "22     Unemployment Rate    0.045846\n",
      "23                  Year    0.034781\n",
      "13          ff_assets_gr    0.034753\n",
      "24                 Month    0.022272\n",
      "15         ff_mkt_val_gr    0.020170\n",
      "18             ff_zscore    0.018073\n",
      "6   ff_inven_curr_assets   -0.012412\n",
      "17           ff_pbk_tang   -0.007051\n",
      "0      FF_PRICE_CLOSE_FP    0.006292\n",
      "25             DayOfWeek   -0.005747\n",
      "11             ff_bps_gr   -0.004808\n",
      "10        ff_sales_wkcap   -0.000000\n",
      "1     ff_debt_entrpr_val   -0.000000\n",
      "14            ff_fcf_yld   -0.000000\n",
      "9            ff_ltd_tcap   -0.000000\n",
      "16           ff_earn_yld   -0.000000\n",
      "8         ff_liabs_lease   -0.000000\n",
      "7          ff_ltd_com_eq   -0.000000\n",
      "19   ff_entrpr_val_sales   -0.000000\n",
      "20         ff_psales_dil   -0.000000\n",
      "5         ff_debt_com_eq   -0.000000\n",
      "4             ff_debt_eq   -0.000000\n",
      "3   ff_fix_assets_com_eq   -0.000000\n",
      "2   ff_tot_debt_tcap_std    0.000000\n",
      "Feature Importances for Fold 5:\n",
      "                 Feature  Importance\n",
      "12      ff_oper_inc_tcap   -0.078723\n",
      "21                   CPI    0.060188\n",
      "22     Unemployment Rate    0.049273\n",
      "13          ff_assets_gr    0.034971\n",
      "23                  Year    0.033978\n",
      "24                 Month    0.027000\n",
      "15         ff_mkt_val_gr    0.025861\n",
      "18             ff_zscore    0.013898\n",
      "25             DayOfWeek   -0.008776\n",
      "6   ff_inven_curr_assets   -0.006576\n",
      "0      FF_PRICE_CLOSE_FP    0.004392\n",
      "17           ff_pbk_tang   -0.001071\n",
      "8         ff_liabs_lease   -0.000000\n",
      "1     ff_debt_entrpr_val   -0.000000\n",
      "14            ff_fcf_yld   -0.000000\n",
      "7          ff_ltd_com_eq   -0.000000\n",
      "16           ff_earn_yld   -0.000000\n",
      "10        ff_sales_wkcap   -0.000000\n",
      "11             ff_bps_gr   -0.000000\n",
      "19   ff_entrpr_val_sales   -0.000000\n",
      "20         ff_psales_dil   -0.000000\n",
      "5         ff_debt_com_eq   -0.000000\n",
      "4             ff_debt_eq   -0.000000\n",
      "3   ff_fix_assets_com_eq   -0.000000\n",
      "2   ff_tot_debt_tcap_std    0.000000\n",
      "9            ff_ltd_tcap    0.000000\n",
      "Feature Importances for Fold 5:\n",
      "                 Feature  Importance\n",
      "12      ff_oper_inc_tcap   -0.076534\n",
      "21                   CPI    0.062802\n",
      "22     Unemployment Rate    0.047277\n",
      "24                 Month    0.030982\n",
      "23                  Year    0.029735\n",
      "13          ff_assets_gr    0.026850\n",
      "18             ff_zscore    0.017729\n",
      "0      FF_PRICE_CLOSE_FP    0.014286\n",
      "25             DayOfWeek   -0.005908\n",
      "6   ff_inven_curr_assets   -0.005509\n",
      "11             ff_bps_gr    0.002937\n",
      "2   ff_tot_debt_tcap_std   -0.000000\n",
      "3   ff_fix_assets_com_eq   -0.000000\n",
      "4             ff_debt_eq   -0.000000\n",
      "5         ff_debt_com_eq   -0.000000\n",
      "20         ff_psales_dil   -0.000000\n",
      "19   ff_entrpr_val_sales   -0.000000\n",
      "8         ff_liabs_lease   -0.000000\n",
      "9            ff_ltd_tcap   -0.000000\n",
      "16           ff_earn_yld    0.000000\n",
      "15         ff_mkt_val_gr    0.000000\n",
      "14            ff_fcf_yld    0.000000\n",
      "1     ff_debt_entrpr_val   -0.000000\n",
      "7          ff_ltd_com_eq   -0.000000\n",
      "10        ff_sales_wkcap   -0.000000\n",
      "17           ff_pbk_tang   -0.000000\n",
      "Feature Importances for Fold 5:\n",
      "                 Feature  Importance\n",
      "12      ff_oper_inc_tcap   -0.074150\n",
      "21                   CPI    0.061115\n",
      "22     Unemployment Rate    0.047942\n",
      "24                 Month    0.031526\n",
      "13          ff_assets_gr    0.029683\n",
      "23                  Year    0.028475\n",
      "18             ff_zscore    0.014495\n",
      "0      FF_PRICE_CLOSE_FP    0.014461\n",
      "25             DayOfWeek   -0.007206\n",
      "6   ff_inven_curr_assets   -0.004132\n",
      "11             ff_bps_gr    0.003070\n",
      "2   ff_tot_debt_tcap_std   -0.000000\n",
      "3   ff_fix_assets_com_eq   -0.000000\n",
      "4             ff_debt_eq   -0.000000\n",
      "5         ff_debt_com_eq   -0.000000\n",
      "20         ff_psales_dil   -0.000000\n",
      "19   ff_entrpr_val_sales   -0.000000\n",
      "8         ff_liabs_lease   -0.000000\n",
      "9            ff_ltd_tcap   -0.000000\n",
      "16           ff_earn_yld    0.000000\n",
      "15         ff_mkt_val_gr    0.000000\n",
      "14            ff_fcf_yld    0.000000\n",
      "1     ff_debt_entrpr_val   -0.000000\n",
      "7          ff_ltd_com_eq   -0.000000\n",
      "10        ff_sales_wkcap   -0.000000\n",
      "17           ff_pbk_tang   -0.000000\n"
     ]
    }
   ],
   "source": [
    "import pyspark.pandas as ps\n",
    "from pyspark.sql.functions import lit,col\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "#from boruta import BorutaPy\n",
    "#from fredapi import Fred\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "def get_macro_features():\n",
    "    # fred_key = 'bdfdde3b7a21b7d528011d17996b0b8e'\n",
    "    # fred = Fred(api_key=fred_key)\n",
    "    # cpi = fred.get_series(series_id='CPIAUCSL')\n",
    "    # cpi_change = cpi.pct_change()\n",
    "    # unemp = fred.get_series(series_id='UNRATE')\n",
    "    # gdp = fred.get_series(series_id='GDP')\n",
    "    # gdp_change = gdp.pct_change()\n",
    "    # df = pd.DataFrame({'CPI_change': cpi_change,'Unemployment_Rate': unemp,'GDP_change': gdp_change})\n",
    "    # df.to_csv('macro.csv')\n",
    "    df = pd.read_csv('macro.csv')\n",
    "    return df\n",
    "\n",
    "def get_all_stocks():\n",
    "    query = f\"\"\"SELECT s.ticker_region, sc.fref_listing_exchange FROM sym_ticker_region s \n",
    "                LEFT JOIN FF_SEC_COVERAGE c ON c.fsym_id = s.fsym_id\n",
    "                LEFT JOIN sym_coverage sc ON sc.fsym_id = s.fsym_id\n",
    "                WHERE s.ticker_region LIKE \"%-US\" AND s.ticker_region NOT LIKE '%.%' AND c.CURRENCY = \"USD\"\n",
    "                AND (sc.fref_listing_exchange = \"NAS\" OR sc.fref_listing_exchange = \"NYS\")\"\"\"\n",
    "    df = spark.sql(query)\n",
    "    df = df.withColumn(\"ticker_region\", regexp_replace(\"ticker_region\", \"-US$\", \"\"))\n",
    "    ticker_list = [row.ticker_region for row in df.collect()]\n",
    "    return ticker_list\n",
    "\n",
    "\n",
    "\n",
    "def get_non_imp_stocks_query():\n",
    "    df2 = spark.createDataFrame(get_implosion_df('imploded_stocks.csv'))\n",
    "    df2.createOrReplaceTempView(\"imp_table\")\n",
    "    query = f\"\"\"SELECT s.ticker_region, s.fsym_id FROM sym_ticker_region s \n",
    "                LEFT JOIN FF_SEC_COVERAGE c ON c.fsym_id = s.fsym_id\n",
    "                LEFT JOIN sym_coverage sc ON sc.fsym_id = s.fsym_id\n",
    "                WHERE s.ticker_region LIKE \"%-US\" AND s.ticker_region NOT LIKE '%.%' AND c.CURRENCY = \"USD\"\n",
    "                AND (sc.fref_listing_exchange = \"NAS\" OR sc.fref_listing_exchange = \"NYS\")\n",
    "                AND NOT EXISTS (\n",
    "                SELECT 1\n",
    "                FROM imp_table\n",
    "                WHERE s.ticker_region = CONCAT(imp_table.Ticker, '-US') )    \n",
    "                \"\"\"\n",
    "    df = spark.sql(query)\n",
    "    print(\"got non imploded stocks\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_implosion_df(filename):\n",
    "    df = pd.read_csv(filename, index_col=False)\n",
    "    df['Implosion_Date'] = pd.to_datetime(df['Implosion_Date'])\n",
    "    return df\n",
    "\n",
    "def get_features_for_imploded_stocks(df, big_string, table):\n",
    "    df=spark.createDataFrame(df)\n",
    "    df.createOrReplaceTempView(\"temp_table\")\n",
    "    # query = \"\"\"SELECT t.Ticker, t.Implosion_Date, t.Implosion_Next_Year, a.date, a.ff_gross_inc, b.date, b.ff_gross_inc, c.date, c.ff_gross_inc\n",
    "    #             FROM temp_table t \n",
    "    #             LEFT JOIN sym_ticker_region s ON s.ticker_region = CONCAT(t.Ticker, '-US')\n",
    "    #             LEFT JOIN FF_BASIC_AF a ON s.fsym_id = a.fsym_id AND YEAR(a.date) = YEAR(t.Implosion_Date)-1\n",
    "    #             LEFT JOIN FF_BASIC_AF b ON s.fsym_id = b.fsym_id AND YEAR(b.date) = YEAR(t.Implosion_Date)-2\n",
    "    #             LEFT JOIN FF_BASIC_AF c ON s.fsym_id = c.fsym_id AND YEAR(c.date) = YEAR(t.Implosion_Date)-3\n",
    "    #             ORDER BY t.Ticker, a.date\n",
    "    # \"\"\"\n",
    "    query = f\"\"\"SELECT t.Ticker, a.date, b.FF_PRICE_CLOSE_FP, {big_string}, t.Implosion_Next_Year FROM temp_table t\n",
    "                    LEFT JOIN sym_ticker_region s ON s.ticker_region = CONCAT(t.Ticker, '-US')\n",
    "                    LEFT JOIN {table} a ON a.fsym_id = s.fsym_id AND YEAR(a.date) = t.Year\n",
    "                    LEFT JOIN FF_BASIC_AF b ON b.fsym_id = s.fsym_id AND YEAR(b.date) = t.Year\n",
    "                    ORDER BY t.Ticker, a.date\n",
    "    \"\"\"\n",
    "    df2 = spark.sql(query)\n",
    "    print(\"imploded query done\")\n",
    "    return df2\n",
    "    \n",
    "    \n",
    "def get_features_for_non_imploded(metric_string, metric_string2,table):\n",
    "    df = get_non_imp_stocks_query()\n",
    "    df.createOrReplaceTempView(\"temp_table\")\n",
    "    query = f\"\"\"WITH RankedData AS (\n",
    "    SELECT\n",
    "        t.ticker_region, t.fsym_id,\n",
    "        a.date,\n",
    "        {metric_string},\n",
    "        ROW_NUMBER() OVER (PARTITION BY t.ticker_region ORDER BY a.date DESC) AS row_num\n",
    "        FROM temp_table t\n",
    "        LEFT JOIN {table} a ON a.fsym_id = t.fsym_id\n",
    "        WHERE YEAR(a.date) < 2023 )\n",
    "    SELECT\n",
    "        r.ticker_region AS Ticker, r.date,  b.FF_PRICE_CLOSE_FP, {metric_string2}\n",
    "        FROM RankedData r\n",
    "        LEFT JOIN FF_BASIC_AF b ON b.fsym_id = r.fsym_id AND YEAR(b.date) = YEAR(r.date)\n",
    "        WHERE row_num <= 1\n",
    "        ORDER BY ticker_region, date\"\"\"\n",
    "    new_df = spark.sql(query)\n",
    "    print(\"non imploded query done\")\n",
    "    return new_df\n",
    "\n",
    "\n",
    "def create_non_imploded_ds(table):\n",
    "    df_metrics = ps.DataFrame(spark.sql(f\"SELECT * FROM {table} LIMIT 10\")) #get all the metrics\n",
    "    # cols = []\n",
    "    # for c in df_metrics.columns:\n",
    "    #     if df_metrics[c].dtype=='float64':#get all the metrics we can calculate correlations with\n",
    "    #         cols.append(c)\n",
    "    cols = ['ff_debt_entrpr_val', 'ff_tot_debt_tcap_std', 'ff_fix_assets_com_eq', 'ff_debt_eq', 'ff_debt_com_eq', 'ff_inven_curr_assets', 'ff_ltd_com_eq', 'ff_liabs_lease', 'ff_ltd_tcap', 'ff_sales_wkcap',\n",
    "           'ff_bps_gr', 'ff_oper_inc_tcap', 'ff_assets_gr', 'ff_fcf_yld', 'ff_mkt_val_gr', 'ff_earn_yld', 'ff_pbk_tang', 'ff_zscore', 'ff_entrpr_val_sales', 'ff_psales_dil'] #advanced_der_qf\n",
    "    \n",
    "    metric_string = ', '.join('a.' + item for item in cols)\n",
    "    metric_string2 = ', '.join('r.' + item for item in cols)\n",
    "    df = get_features_for_non_imploded(metric_string, metric_string2, table)\n",
    "    df = df.withColumn(\"Implosion_Next_Year\", lit(0))\n",
    "    return df\n",
    "\n",
    "def create_imploded_df(table):\n",
    "    df = get_implosion_df('imploded_stocks.csv')\n",
    "    df = df.drop(df.columns[0], axis=1)\n",
    "    df['Implosion_Year'] = df['Implosion_Date'].dt.year-1\n",
    "    df['Implosion_Next_Year'] = 1\n",
    "    # additional_rows_1 = df.copy()\n",
    "    # additional_rows_1['Implosion_Year'] = df['Implosion_Year'] - 1\n",
    "    # additional_rows_1['Implosion_Next_Year'] = 0\n",
    "    # additional_rows_2 = df.copy()\n",
    "    # additional_rows_2['Implosion_Year'] = df['Implosion_Year'] - 2\n",
    "    # additional_rows_2['Implosion_Next_Year'] = 0\n",
    "    # additional_rows_3 = df.copy()\n",
    "    # additional_rows_3['Implosion_Year'] = df['Implosion_Year'] - 3\n",
    "    # additional_rows_3['Implosion_Next_Year'] = 0\n",
    "    # df = pd.concat([df, additional_rows_1, additional_rows_2, additional_rows_3])\n",
    "    df = df.sort_values(by=['Ticker', 'Implosion_Year'])\n",
    "    df = df.reset_index(drop=True)\n",
    "    df =df.rename({'Implosion_Year' : 'Year'},axis=1)\n",
    "    \n",
    "    # df_metrics = ps.DataFrame(spark.sql(f\"SELECT * FROM {table} LIMIT 10\")) #get all the metrics\n",
    "    # cols = []\n",
    "    # for c in df_metrics.columns:\n",
    "    #     if df_metrics[c].dtype=='float64':#get all the metrics we can calculate correlations with\n",
    "    #         cols.append(c)\n",
    "    \n",
    "    cols = ['ff_debt_entrpr_val', 'ff_tot_debt_tcap_std', 'ff_fix_assets_com_eq', 'ff_debt_eq', 'ff_debt_com_eq', 'ff_inven_curr_assets', 'ff_ltd_com_eq', 'ff_liabs_lease', 'ff_ltd_tcap', 'ff_sales_wkcap',\n",
    "           'ff_bps_gr', 'ff_oper_inc_tcap', 'ff_assets_gr', 'ff_fcf_yld', 'ff_mkt_val_gr', 'ff_earn_yld', 'ff_pbk_tang', 'ff_zscore', 'ff_entrpr_val_sales', 'ff_psales_dil'] #advanced_der_qf\n",
    "    \n",
    "    metric_string = ', '.join('a.' + item for item in cols)\n",
    "    \n",
    "    df = get_features_for_imploded_stocks(df, metric_string, table)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def boruta_fs():\n",
    "    result_df = pd.read_csv('Advanced_AF_DER_Dataset.csv', index_col=None)\n",
    "    X = result_df.drop(['Ticker', 'date', 'Implosion_Next_Year'], axis=1)\n",
    "    Y = result_df['Implosion_Next_Year']\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X)\n",
    "    X=scaler.transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.2, random_state=42)\n",
    "    \n",
    "    model = xgb.XGBClassifier()\n",
    "    feat_selector = BorutaPy(model, n_estimators='auto', verbose=2, random_state=1)\n",
    "    feat_selector.fit(X_train, y_train)\n",
    "    \n",
    "    print(feat_selector.support_)\n",
    "    print(feat_selector.ranking_)\n",
    "    \n",
    "    \n",
    "def lasso_fs():\n",
    "    result_df = pd.read_csv('Advanced_AF_DER_Dataset.csv', index_col=None)\n",
    "    result_df['date'] = pd.to_datetime(result_df['date'])\n",
    "    result_df['Year'] = result_df['date'].dt.year\n",
    "    result_df['Month'] = result_df['date'].dt.month\n",
    "    result_df['DayOfWeek'] = result_df['date'].dt.dayofweek\n",
    "    X = result_df.drop(['Ticker', 'date', 'Implosion_Next_Year'], axis=1)\n",
    "    cols = X.columns\n",
    "    print(X.head())\n",
    "    Y = result_df['Implosion_Next_Year']\n",
    "\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "    for train_index, test_index in tscv.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = Y.iloc[train_index], Y.iloc[test_index]\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X_train)\n",
    "        X_train_scaled = scaler.transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "        alpha = 0.01\n",
    "        lasso_model = Lasso(alpha=alpha)\n",
    "        lasso_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "        feature_importances = lasso_model.coef_\n",
    "\n",
    "        feature_importance_df = pd.DataFrame({'Feature': cols, 'Importance': feature_importances})\n",
    "\n",
    "        feature_importance_df['Absolute Importance'] = feature_importance_df['Importance'].abs()\n",
    "        feature_importance_df = feature_importance_df.sort_values(by='Absolute Importance', ascending=False).drop('Absolute Importance', axis=1)\n",
    "        print(f'Feature Importances for Fold {tscv.get_n_splits()}:')\n",
    "        print(feature_importance_df)\n",
    "    \n",
    "\n",
    "def create_dataset(table):\n",
    "    # df = get_implosion_df('imploded_stocks.csv')\n",
    "    # df = df.drop(df.columns[0], axis=1)\n",
    "    # df['Implosion_Year'] = df['Implosion_Date'].dt.year\n",
    "    # df['Implosion_Next_Year'] = 1\n",
    "    # get_features_for_imploded_stocks(df)\n",
    "    #print(df.head())\n",
    "    #df=spark.createDataFrame(df)\n",
    "    #df.createOrReplaceTempView(\"temp_table\")\n",
    "    \n",
    "    imp_df = create_imploded_df(table).toPandas()\n",
    "    non_imp_df =create_non_imploded_ds(table).toPandas()\n",
    "    result_df = pd.concat([non_imp_df,imp_df], ignore_index=True)\n",
    "    #print(result_df.head())\n",
    "    result_df['date'] = pd.to_datetime(result_df['date'], format='%Y-%m-%d')\n",
    "    result_df=result_df.sort_values(by=['Ticker','date'])\n",
    "    macro_df = get_macro_features().reset_index()\n",
    "    macro_df['Date'] = pd.to_datetime(macro_df['Date'], format='%d/%m/%Y')\n",
    "    #print(macro_df.head())\n",
    "    result_df['month_year'] = result_df['date'].dt.to_period(\"M\")\n",
    "    macro_df['Month_year'] = macro_df['Date'].dt.to_period(\"M\")\n",
    "    result_df = pd.merge(result_df, macro_df, left_on='month_year', right_on='Month_year', how='left')\n",
    "    result_df.drop(['Date', 'index', 'month_year','Month_year','GDP'],axis=1,inplace=True)\n",
    "    \n",
    "    print(result_df.head())\n",
    "    \n",
    "    null_pcts = result_df.isnull().sum()/len(result_df)\n",
    "    \n",
    "    cols_to_drop = null_pcts[null_pcts > 0.5].index.tolist()\n",
    "    result_df.drop(cols_to_drop,axis=1,inplace=True)\n",
    "    print(\"dropped cols: \", cols_to_drop)\n",
    "    \n",
    "    result_df=pd.DataFrame(result_df)\n",
    "    print(\"before dropping nulls: \",len(result_df))\n",
    "    result_df = result_df.dropna()\n",
    "    print(\"after dropping nulls: \", len(result_df))\n",
    "    print(\"number of implosions: \", len(result_df[result_df['Implosion_Next_Year']==1]))\n",
    "    print(\"number of non-implosions: \", len(result_df[result_df['Implosion_Next_Year']==0]))\n",
    "    result_df.to_csv('Advanced_AF_DER_Dataset.csv', index=False)\n",
    "    print(\"dataset written\")\n",
    "    \n",
    "#     result_df = ps.DataFrame(result_df)\n",
    "#     X = result_df.drop(['Ticker', 'date', 'Implosion_Next_Year'], axis=1)\n",
    "#     y = result_df['Implosion_Next_Year']\n",
    "#     scaler = StandardScaler()\n",
    "#     scaler.fit(X)\n",
    "#     X=scaler.transform(X)\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.2, random_state=42)\n",
    "    \n",
    "#     model = xgb.XGBClassifier()\n",
    "#     feat_selector = BorutaPy(model, n_estimators='auto', verbose=2, random_state=1)\n",
    "#     feat_selector.fit(X_train, y_train)\n",
    "    \n",
    "#     print(feat_selector.support_)\n",
    "#     print(feat_selector.ranking_)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "create_dataset('FF_ADVANCED_DER_AF')\n",
    "#boruta_fs()\n",
    "lasso_fs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d7337e-6ca2-4212-b9d0-17953b8998d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
