{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Database(name='2022_10_22', catalog='spark_catalog', description='FactSet data version for the day', locationUri='hdfs://bialobog.cs.ucl.ac.uk:8020/user/hive/warehouse'),\n",
       " Database(name='2023_04_01', catalog='spark_catalog', description='FactSet data version for the day', locationUri='hdfs://bialobog.cs.ucl.ac.uk:8020/user/hive/warehouse'),\n",
       " Database(name='default', catalog='spark_catalog', description='Default Hive database', locationUri='hdfs://bialobog.cs.ucl.ac.uk:8020/user/hive/warehouse')]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "import pandas as pd\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf\n",
    "\n",
    "# for shared metastore (shared across all users)\n",
    "spark = SparkSession.builder.appName(\"Identification\").config(\"hive.metastore.uris\", \"thrift://bialobog:9083\", conf=SparkConf()).getOrCreate() \\\n",
    "\n",
    "# for local metastore (your private, invidivual database) add the following config to spark session\n",
    "\n",
    "spark.catalog.listDatabases()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155276\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import regexp_replace\n",
    "\n",
    "spark.sql(\"USE 2023_04_01\")\n",
    "    # Assuming that 'ticker' is a valid Python variable\n",
    "\n",
    "query = f\"\"\"SELECT ticker_region FROM sym_ticker_region WHERE ticker_region LIKE \"%-US\" AND ticker_region NOT LIKE '%.%' \"\"\"\n",
    "df = spark.sql(query)\n",
    "df = df.withColumn(\"ticker_region\", regexp_replace(\"ticker_region\", \"-US$\", \"\"))\n",
    "ticker_list = [row.ticker_region for row in df.collect()]\n",
    "print(len(ticker_list))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AMTCQ', 'AACJWXX', 'FKLBDX', 'FCTFHX', 'FGLVJX', 'ESMT', 'SCEGX', 'ISSSF', 'WNGPF', 'MS5044160', 'SPROW', 'CUVATX', 'RBLTX', 'GIBBF', 'ENIC', 'FSSEX', 'JMPC', 'SFR', 'CCSZX', 'UBS4967480', 'EOBK', 'PDKFX', 'GWLLF', 'GECC', 'UBS5042838', 'VGRQX', 'FLMFX', 'EMCMF', 'PTICX', 'CEUHIX', 'IAPCX', 'LSAVX', 'AZNAX', 'BGGNF', 'PKTEX', 'FSFSX', 'ERND20', 'AVCWQ', 'TSBK', 'KIIIU', 'GMOXX', 'PRFU', 'FOCT', 'ACLLF', 'MPLD', 'ICMPX', 'RBSPF', 'OSIS', 'USWG', 'PSCD', 'PROS38', 'LSCVX', 'MDMXF', 'EGSIX', 'EIVDX', 'EGPCU', 'PRCS', 'FDPXX', 'ACGBF', 'SUSMF', 'AGLFQ', 'MGAWF', 'APWD', 'WELL78', 'ANORX', 'GNWTP', 'IRBGY', 'RCACX', 'ISPISX', 'NDGPY', 'UBQPBX', 'SBROF', 'OILFF', 'PGVTX', 'EFRMF', 'ECBDX', 'CNACX', 'JPYOZ', 'SSHZ', 'FAUIX', 'PKRDQ', 'AICIX', 'XCADX', 'BZFDW', 'SIVVU', 'PDVG', 'FSUVX', 'SWNM', 'AACPRXX', 'SPSS', 'WFHRX', 'MBGCF', 'BDH', 'YYCIV', 'HYNLZ', 'THLIX', 'FHNEAX', 'YQUFF', 'BIIVF', 'BYL923']\n"
     ]
    }
   ],
   "source": [
    "print(ticker_list[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------+\n",
      "|Ticker|Implosion_Date|\n",
      "+------+--------------+\n",
      "| EMCMF|    2022-09-04|\n",
      "| MGAWF|    2022-10-30|\n",
      "| MBGCF|    2016-10-02|\n",
      "| MBGCF|    2018-05-06|\n",
      "| MBGCF|    2022-04-03|\n",
      "|  SWNM|    2022-04-10|\n",
      "+------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import yfinance as yf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from datetime import datetime\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.stats import norm\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import col, to_date, lit\n",
    "from datetime import timedelta\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DateType\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "\n",
    "imploded_stocks = pd.read_csv('filtered_tickers.csv')\n",
    "imploded_stocks = imploded_stocks['Ticker'].tolist()\n",
    "\n",
    "sp500_stocks = pd.read_csv('constituents.csv', usecols=['Symbol'])\n",
    "sp500_stocks = sp500_stocks['Symbol'].tolist()\n",
    "\n",
    "start_date = '2009-01-01'\n",
    "end_date = datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "def get_stock_price_weekly(ticker):\n",
    "    # Suppress the progress message from yfinance\n",
    "    temp_df = yf.download(ticker, start=start_date, end=end_date, progress=False)\n",
    "    if temp_df.empty:\n",
    "        #print(\"No data available for the specified date range.\")\n",
    "        return None\n",
    "    weekly_data = temp_df['Adj Close'].resample('W').last()\n",
    "    return weekly_data\n",
    "\n",
    "def check_implosion(idx, firm_price, imp_thresh):\n",
    "    i = idx\n",
    "    start_price=firm_price.iloc[idx]\n",
    "    i+=1\n",
    "    period=0\n",
    "    while i < len(firm_price):\n",
    "        current_date = firm_price.index[i]\n",
    "        current_price = firm_price.iloc[i]\n",
    "        if (current_price-start_price)/start_price > -imp_thresh/2:\n",
    "            return period\n",
    "        period+=1\n",
    "        i+=1\n",
    "    return period\n",
    "\n",
    "def get_crash_dates(firm_price, price_drop_thresh=-0.6, period_thresh=52):\n",
    "    crash_dates = []\n",
    "    imp_dates = []\n",
    "    i = 52\n",
    "    while i < len(firm_price):\n",
    "        current_date = firm_price.index[i]\n",
    "        current_price = firm_price.iloc[i]\n",
    "        prev_year_data = firm_price.iloc[i-52:i]\n",
    "        if len(prev_year_data) != 0:\n",
    "            mean_price = prev_year_data.mean()\n",
    "            if (current_price - mean_price)/mean_price < price_drop_thresh:\n",
    "                imp_dates.append(current_date)\n",
    "        i+=1\n",
    "    return imp_dates\n",
    "\n",
    "def get_implosion_dates(firm_price, price_drop_thresh=-0.6, period_thresh=52):\n",
    "    crash_dates = []\n",
    "    imp_dates = []\n",
    "    i = 52\n",
    "    while i < len(firm_price):\n",
    "        current_date = firm_price.index[i]\n",
    "        current_price = firm_price.iloc[i]\n",
    "        prev_year_data = firm_price.iloc[i-52:i]\n",
    "        if len(prev_year_data) != 0:\n",
    "            mean_price = prev_year_data.mean()\n",
    "            if (current_price - mean_price)/mean_price < price_drop_thresh:\n",
    "                imp_period = check_implosion(i, firm_price,  price_drop_thresh)\n",
    "                if imp_period > period_thresh:\n",
    "                    imp_dates.append((current_date, firm_price.index[i+imp_period]))\n",
    "                i+=imp_period\n",
    "        i+=1\n",
    "    return imp_dates\n",
    "\n",
    "def plot_implosions(stock_series, imp_dates, ticker):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.plot(stock_series.index, stock_series, label=ticker)\n",
    "    for i in imp_dates:\n",
    "        plt.axvspan(i[0], i[1], alpha=0.5, color='blue')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def run_imps(stocks_list):\n",
    "    num_imp = 0\n",
    "    j = 0\n",
    "    for t in stocks_list:\n",
    "        stock_series = get_stock_price_weekly(t)\n",
    "        if stock_series is not None:\n",
    "            imp_dates = get_implosion_dates(stock_series)\n",
    "            # if j % 10 == 0:\n",
    "            #     plot_implosions(stock_series, imp_dates, t)    \n",
    "            j+=1\n",
    "            if len(imp_dates) >= 1:\n",
    "                num_imp+=1\n",
    "            # if len(imp_dates) ==0:\n",
    "            #     plot_implosions(stock_series, imp_dates, t)\n",
    "    print(f\"{num_imp} out of {j} imploded\")\n",
    "    return num_imp\n",
    "\n",
    "def plot_crashes(ticker):\n",
    "    stock_series = get_stock_price_weekly(ticker)\n",
    "    crash_dates = get_crash_dates(stock_series)\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.plot(stock_series.index, stock_series, label=ticker)\n",
    "    for c in crash_dates:\n",
    "        plt.axvspan(c,c, alpha=0.5, color='blue')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def create_imploded_df(ticker_list):\n",
    "    schema = StructType([StructField(\"Ticker\", StringType(), True),\n",
    "                     StructField(\"Implosion_Date\", StringType(), True)])\n",
    "    df = spark.read.csv('imploded_tickers_dates.csv', header=True, inferSchema=True)\n",
    "    df.show(100)\n",
    "#     for t in ticker_list:\n",
    "#         stock_series = get_stock_price_weekly(t)\n",
    "#         if stock_series is not None:\n",
    "#             imp_dates = get_implosion_dates(stock_series)\n",
    "#             if len(imp_dates)!=0:\n",
    "#                 for date in imp_dates:\n",
    "                    \n",
    "#                     date_str = pd.to_datetime(date[0]).strftime('%Y-%m-%d')\n",
    "#                     #date = to_date(date[0],'yyyy-MM-dd')\n",
    "#                     row = Row(Ticker=t, Implosion_Date=date_str)\n",
    "#                     df = df.union(spark.createDataFrame([row],schema=schema))\n",
    "#             # if len(imp_dates)!= 0: \n",
    "#             #     for d in imp_dates:\n",
    "#             #         date = d[0]\n",
    "#             #         df = df.withColumn('Imploded',when((col('Ticker') == t) & (year('Date') == date.year) & (month('Date') == date.month),1\n",
    "#             #             ).otherwise(col('Imploded'))) \n",
    "#     print(df.show(10))           \n",
    "#     df.toPandas().to_csv('imploded_tickers_dates.csv', index='False')\n",
    "    \n",
    "\n",
    "create_imploded_df(ticker_list)\n",
    "#run_imps(['A'])\n",
    "#add_labels_to_df('imploded_only.csv')\n",
    "#plot_crashes('SEAC')\n",
    "#APPN,CPS, FOSL, GRPN,PRLB, SEAC\n",
    "#APPN has not imploded\n",
    "#CPS has not imploded\n",
    "#imploded: 377/433, sp500:  russell: 243/1754 imploded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv\n",
    "\n",
    "# def save_weekly_prices():\n",
    "#     filtered_tickers = []  # A list to store the ticker names\n",
    "\n",
    "#     for ticker in russell_stocks:\n",
    "#         t_df = get_stock_price_weekly(ticker)\n",
    "#         if t_df is not None:\n",
    "#             max_price = max(t_df)  # Replace 'price' with the actual column name\n",
    "#             if max_price >= 100:\n",
    "#                 filtered_tickers.append(ticker)\n",
    "\n",
    "#     csv_file_name = 'filtered_russell_tickers.csv'\n",
    "\n",
    "#     # Open the CSV file in write mode\n",
    "#     with open(csv_file_name, mode='w', newline='') as file:\n",
    "#         writer = csv.writer(file)  # Create a CSV writer object\n",
    "\n",
    "#         # Write the ticker names to the CSV file\n",
    "#         writer.writerow(['Ticker'])  # Write a header row\n",
    "#         for ticker in filtered_tickers:\n",
    "#             writer.writerow([ticker])\n",
    "\n",
    "# save_weekly_prices()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
