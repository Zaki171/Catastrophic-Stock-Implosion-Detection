{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b862fd7-75a8-4818-95c2-5375dde4b345",
   "metadata": {},
   "source": [
    "## IF Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda6c879-2ecc-475a-9f90-99bccea780bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "import pandas as pd\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf\n",
    "\n",
    "# for shared metastore (shared across all users)\n",
    "spark = SparkSession.builder.appName(\"Seq\").config(\"hive.metastore.uris\", \"thrift://amok:9083\", conf=SparkConf()).getOrCreate() \\\n",
    "\n",
    "# for local metastore (your private, invidivual database) add the following config to spark session\n",
    "spark.sql(\"USE 2023_11_02\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54391b05-47b8-4d4b-b943-eda194771996",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import pyspark.pandas as ps\n",
    "from pyspark.sql.functions import lit,col\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import xgboost as xgb\n",
    "#from boruta import BorutaPy\n",
    "#from fredapi import Fred\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import csv\n",
    "from pyspark.sql import functions as F\n",
    "from functools import reduce\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier, GBTClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder, CrossValidatorModel\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "from CreateDataset import get_full_seqs, get_seq_means"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4488aa6-4e95-4df0-9a73-01ef0fd83d5f",
   "metadata": {},
   "source": [
    "## Aggregating Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba39e2b3-07f5-4fd9-adf5-735d881bf565",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('imploded_stocks_price.csv', index_col=False)\n",
    "df['Implosion_Start_Date'] = pd.to_datetime(df['Implosion_Start_Date'])\n",
    "df['Implosion_End_Date'] = pd.to_datetime(df['Implosion_End_Date'])\n",
    "df = get_seq_means(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30d429c-7d3d-4325-bc80-2471074b13ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea494ba3-ea41-4f87-af29-462b30f15627",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(df.count())\n",
    "print(df.filter(col('label') == 1).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a4c64d-dc1b-41a4-bfe9-8711934116e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "null_counts = df.select([F.sum(col(column).isNull().cast(\"int\")).alias(column + \"_null_count\") for column in df.columns])\n",
    "result_df = null_counts.toPandas()\n",
    "result_df = result_df.transpose()\n",
    "result_df.columns = ['Null Count']\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09a947a-3874-46f7-9dd4-aaca20cbc498",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.drop('ff_zscore', 'ff_mkt_val_gr','ff_mkt_val_public', 'ff_emp_gr', 'ff_sales_fix_assets', 'ff_cf_ps_gr', 'ff_shs_float', 'ff_sga_oth', 'ff_fcf_yld', 'ff_net_inc_per_emp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e7c04c-6dc4-4ac2-a544-5e3c187cfaaf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(df.count())\n",
    "print(df.dropna().count())\n",
    "print(df.dropna().filter(col('label')==1).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cea0250-5dde-4ce9-8d99-3776bb8aac37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df=df.dropna()\n",
    "print(df.count())\n",
    "print(df.filter(col('label')==1).count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546c5c10-3723-4b88-9add-8a6fdebafc17",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63645eaf-dfa5-43d5-ab36-e94c6ced8c79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def t_t_split(df):\n",
    "    train, test = df.randomSplit([0.8,0.2])\n",
    "    return train, test\n",
    "\n",
    "\n",
    "def confusion_matrix_pandas(df):\n",
    "    df = df.toPandas()\n",
    "    cm = confusion_matrix(df['label'], df['prediction'])\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Predicted 0', 'Predicted 1'], yticklabels=['Actual 0', 'Actual 1'])\n",
    "    plt.title(f'Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.show()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb392cd-c08f-4884-bf9d-80ef508a15ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, hp\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "import csv\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from itertools import chain\n",
    "    \n",
    "def model_training(df, classifier):\n",
    "    \n",
    "    print(\"Number of records: \", df.count())\n",
    "    \n",
    "    features = df.columns[1:-1]\n",
    "    \n",
    "    train_df, test_df = t_t_split(df)\n",
    "    \n",
    "        \n",
    "    def compute_weights(train_df):\n",
    "        y_collect = train_df.select(\"label\").groupBy(\"label\").count().collect()\n",
    "        unique_y = [x[\"label\"] for x in y_collect]\n",
    "        total_y = sum([x[\"count\"] for x in y_collect])\n",
    "        unique_y_count = len(y_collect)\n",
    "        bin_count = [x[\"count\"] for x in y_collect]\n",
    "\n",
    "        class_weights_spark = {i: ii for i, ii in zip(unique_y, total_y / (unique_y_count * np.array(bin_count)))}\n",
    "        print(class_weights_spark)\n",
    "        mapping_expr = F.create_map([F.lit(x) for x in chain(*class_weights_spark.items())])\n",
    "        train_df = train_df.withColumn(\"weight\", mapping_expr.getItem(F.col(\"label\")))\n",
    "        return train_df\n",
    "        \n",
    "    train_df = compute_weights(train_df)\n",
    "    \n",
    "    vector_assembler = VectorAssembler(inputCols=features, outputCol=\"features_vector\")\n",
    "    train_df = vector_assembler.transform(train_df)\n",
    "    test_df = vector_assembler.transform(test_df)\n",
    "\n",
    "    if classifier == 'LogisticRegression':\n",
    "        param_space = {\n",
    "            'regParam': hp.uniform('regParam', 0.01, 1.0),\n",
    "            'elasticNetParam': hp.uniform('elasticNetParam', 0.0, 1.0)\n",
    "        }\n",
    "        classifier_instance = LogisticRegression(featuresCol=\"features_vector\", labelCol=\"label\", weightCol='weight')\n",
    "    elif classifier == 'RandomForest':\n",
    "        param_space = {\n",
    "            'maxBins': hp.quniform('maxBins', 16, 32, 1),\n",
    "            'maxDepth': hp.quniform('maxDepth', 20, 30, 1)\n",
    "        }\n",
    "        classifier_instance = RandomForestClassifier(featuresCol='features_vector', labelCol='label', weightCol='weight')\n",
    "    elif classifier == 'GBT':\n",
    "        param_space = {\n",
    "            'maxDepth' : hp.quniform(\"maxDepth\", 3, 18, 1),\n",
    "            'maxBins': hp.quniform('maxBins', 16, 32, 1)\n",
    "        }\n",
    "        classifier_instance = GBTClassifier(featuresCol='features_vector', labelCol='label')\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported classifier\")\n",
    "    \n",
    "    initial_model = classifier_instance\n",
    "    initial_model = initial_model.fit(train_df)\n",
    "\n",
    "    def cross_val_train(params):\n",
    "        classifier_instance.setParams(**params)\n",
    "        evaluator = BinaryClassificationEvaluator(metricName='areaUnderPR')\n",
    "        train, val = train_df.randomSplit([0.9,0.1])\n",
    "        curr_model = classifier_instance.fit(train)\n",
    "        predictions = curr_model.transform(val)\n",
    "        val_metric = evaluator.evaluate(predictions)\n",
    "        return curr_model, val_metric\n",
    "#         crossval = CrossValidator(estimator=classifier_instance,\n",
    "#                                   estimatorParamMaps=[params],\n",
    "#                                   evaluator=evaluator,\n",
    "#                                   numFolds=5, parallelism=12)\n",
    "        \n",
    "#         cv_model = crossval.fit(train_df)\n",
    "#         predictions = cv_model.transform(train_df)\n",
    "#         val_metric = evaluator.evaluate(predictions)\n",
    "#         return cv_model, val_metric\n",
    "    \n",
    "    \n",
    "    def objective(params):\n",
    "        model, metric = cross_val_train(params)\n",
    "        return -metric\n",
    "\n",
    "    # Find the best hyperparameters\n",
    "    best_params = fmin(fn=objective, space=param_space, algo=tpe.suggest, max_evals=3)\n",
    "    print(\"Best hyperparameters: \", best_params)\n",
    "\n",
    "    # Train the model with the best hyperparameters\n",
    "    best_model, final_metric = cross_val_train(best_params)\n",
    "            \n",
    "    \n",
    "    predictions = best_model.transform(test_df)\n",
    "    true = predictions.select('label').toPandas()\n",
    "    preds = predictions.select('prediction').toPandas()\n",
    "    print(classification_report(true, preds))\n",
    "    \n",
    "    cm = confusion_matrix(true, preds)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", linewidths=.5)\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "    \n",
    "    return best_model, train_df, test_df\n",
    "    \n",
    "model, train_df, test_df = model_training(df, 'GBT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cb5b36-ced5-415b-b644-d584b50f3425",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "def feat_analysis(model):\n",
    "    features = df.columns[1:-1]\n",
    "    feature_importances = model.featureImportances\n",
    "    feature_importances = feature_importances.toArray()\n",
    "    sorted_idx = np.argsort(feature_importances)[::-1]\n",
    "    sorted_features = [features[i] for i in sorted_idx]\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(range(len(feature_importances)), feature_importances[sorted_idx], align=\"center\")\n",
    "    plt.xticks(range(len(feature_importances)), sorted_features, rotation=45, ha=\"right\")\n",
    "    plt.xlabel(\"Feature\")\n",
    "    plt.ylabel(\"Feature Importance\")\n",
    "    plt.title(\"Feature Importances\")\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def shapley(model, train, test):\n",
    "    exclude_columns = ['fsym_id',  'label', 'features_vector']\n",
    "    train = train.toPandas()\n",
    "    test = test.toPandas()\n",
    "    X_train = train.drop(exclude_columns, axis=1)\n",
    "    X_test = test.drop(exclude_columns, axis=1)\n",
    "    explainer = shap.Explainer(model)\n",
    "    shap_values = explainer.shap_values(X_test)\n",
    "    shap.initjs()\n",
    "    # print(shap_values.shape)\n",
    "    shap.summary_plot(shap_values, X_test)\n",
    "    \n",
    "    \n",
    "# feat_analysis(model)\n",
    "shapley(model, train_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949712bb-7172-47f5-838b-ef9e3a76e723",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "def anomaly_det(df):\n",
    "    train_df, test_df = t_t_split(df)\n",
    "    features = df.columns[1:-1]\n",
    "    train_df = train_df.toPandas()\n",
    "    test_df = test_df.toPandas()\n",
    "    print(\"Converted to Pandas\")\n",
    "    \n",
    "    num_pos = len(train_df[train_df['label']==1])\n",
    "    isol_for = IsolationForest(contamination=num_pos/len(train_df), random_state=41)\n",
    "    isol_for.fit(train_df[features])\n",
    "    train_df['anomaly_scores'] = isol_for.decision_function(train_df[features])\n",
    "    train_df['anomaly'] = isol_for.predict(train_df[features])\n",
    "    train_df['preds'] = np.where(train_df['anomaly'] == 1, 0, 1)\n",
    "    \n",
    "    test_df['anomaly_scores'] = isol_for.decision_function(test_df[features])\n",
    "    test_df['anomaly'] = isol_for.predict(test_df[features])\n",
    "    test_df['preds'] = np.where(test_df['anomaly'] == 1, 0, 1)\n",
    "    \n",
    "    print(train_df)\n",
    "    print(f\"Classification Report: \")\n",
    "    print(classification_report(test_df['label'], test_df['preds']))\n",
    "    cm = confusion_matrix(test_df['label'], test_df['preds'])\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", linewidths=.5)\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "anomaly_det(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e789fde-d2f0-4b56-aaaf-52b7f5eb991b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('imploded_stocks_price.csv', index_col=False)\n",
    "df['Implosion_Start_Date'] = pd.to_datetime(df['Implosion_Start_Date'])\n",
    "df['Implosion_End_Date'] = pd.to_datetime(df['Implosion_End_Date'])\n",
    "df = get_full_seqs(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54066fcc-34e4-4301-80b5-a7be10c91402",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8882a899-98b5-4b95-ba1c-5de2a137a0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "def nn_prepare_seqs(df):\n",
    "    # print(df.columns)\n",
    "    print(\"Number of records: \", df.count())\n",
    "    df = df.filter(reduce(lambda acc, column: acc & (F.size(col(column)) == 22), df.columns[1:-1], F.lit(True)))\n",
    "    print(\"Number of records: \", df.count())\n",
    "    features = df.columns[1:-1]\n",
    "    print(features)\n",
    "    label_col = 'label'\n",
    "\n",
    "    def convert_to_np_array(row):\n",
    "        seq_feats = row.seq_feats\n",
    "        label = row.label\n",
    "        feat_length = len(seq_feats[0])\n",
    "        date_length = len(seq_feats[0][0])\n",
    "        seq_array = np.zeros((feat_length, date_length))\n",
    "        for i, sublist in enumerate(seq_feats[0]):\n",
    "            seq_array[i, :] = np.array(sublist)\n",
    "        seq_array = seq_array.T\n",
    "        return (seq_array, label)\n",
    "    \n",
    "    # train_seqs_rdd = grouped_data.rdd.map(convert_to_np_array)\n",
    "    train_df, test_df = t_t_split(df)\n",
    "    \n",
    "    # train_seqs = []\n",
    "    # for stock_id, group in df.groupby('fsym_id'):\n",
    "    #     seq_feats = group[features]\n",
    "    #     label = group['label']\n",
    "    #     feat_length = len(seq_feats.iloc[0])\n",
    "    #     date_length = len(seq_feats.iloc[0,0])\n",
    "    #     seq_array = np.zeros((feat_length, date_length))\n",
    "    #     for i, sublist in enumerate(seq_feats.columns):\n",
    "    #         seq_array[i, :] = np.array(seq_feats[sublist].iloc[0])\n",
    "    #     seq_array = seq_array.T\n",
    "    #     train_seqs.append((seq_array, label))\n",
    "        \n",
    "        \n",
    "    # df= df.toPandas()\n",
    "    # print(df.head())\n",
    "    # features = df.columns[1:-1]\n",
    "    # list_to_vector_udf = udf(lambda l: Vectors.dense(l), VectorUDT())\n",
    "    # df = df.toPandas()\n",
    "    \n",
    "    \n",
    "    \n",
    "    # for f in features:\n",
    "    #     df = df.withColumn(f, list_to_vector_udf(f))\n",
    "    # train_df, test_df = train_test_split(df)\n",
    "    train_df = train_df.toPandas()\n",
    "    test_df = test_df.toPandas()\n",
    "    \n",
    "    train_seqs = []\n",
    "    for stock_id, group in train_df.groupby('fsym_id'):\n",
    "        seq_feats = group[features]\n",
    "        label = group['label']\n",
    "        feat_length = len(seq_feats.iloc[0])\n",
    "        date_length = len(seq_feats.iloc[0,0])\n",
    "        seq_array = np.zeros((feat_length, date_length))\n",
    "        for i, sublist in enumerate(seq_feats.columns):\n",
    "            seq_array[i, :] = np.array(seq_feats[sublist].iloc[0])\n",
    "        seq_array = seq_array.T\n",
    "        train_seqs.append((seq_array, label))\n",
    "        \n",
    "    test_seqs = []\n",
    "    for stock_id, group in test_df.groupby('fsym_id'):\n",
    "        seq_feats = group[features]\n",
    "        label = group['label']\n",
    "        feat_length = len(seq_feats.iloc[0])\n",
    "        date_length = len(seq_feats.iloc[0,0])\n",
    "        seq_array = np.zeros((feat_length, date_length))\n",
    "        for i, sublist in enumerate(seq_feats.columns):\n",
    "            seq_array[i, :] = np.array(seq_feats[sublist].iloc[0])\n",
    "        seq_array = seq_array.T\n",
    "        test_seqs.append((seq_array, label))\n",
    "    \n",
    "    return train_seqs, test_seqs\n",
    "\n",
    "def plot_model_performance(mdl, loss, metric):\n",
    "    x = pd.DataFrame(mdl.history).reset_index()\n",
    "    x = pd.melt(x, id_vars='index')\n",
    "    x['validation'] = (x['variable'].str[:4] == 'val_').replace({True:'validation',False:'training'})\n",
    "    x['loss'] = (x['variable'].str[-4:] == 'loss').replace({True:loss,False:metric})\n",
    "    g = sns.FacetGrid(x, col='loss', hue='validation',sharey=False)\n",
    "    g.map(sns.lineplot, 'index','value')\n",
    "    g.add_legend()\n",
    "    return g\n",
    "\n",
    "def nn_training(train_seqs, test_seqs):\n",
    "    train_X, train_y = zip(*train_seqs)\n",
    "    test_X, test_y = zip(*test_seqs)\n",
    "\n",
    "    # Convert lists to numpy arrays\n",
    "    train_X = np.array(train_X)\n",
    "    train_y = np.array(train_y)\n",
    "    test_X = np.array(test_X)\n",
    "    test_y = np.array(test_y)\n",
    "    print(np.sum(test_y==1))\n",
    "    \n",
    "    class_labels = np.unique(train_y)\n",
    "    class_weights = compute_class_weight('balanced', classes=class_labels, y=train_y.flatten())\n",
    "    class_weight_dict = dict(zip(class_labels, class_weights))\n",
    "    print(class_weight_dict)\n",
    "    \n",
    "\n",
    "    # Define the neural network model\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(train_X.shape[1], train_X.shape[2])),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(32, activation='relu'),  # Additional Dense layer\n",
    "        tf.keras.layers.Dropout(0.5),  # Dropout layer for regularization\n",
    "        tf.keras.layers.Dense(16, activation='relu'),  # Another Dense layer\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    loss_fn = keras.losses.BinaryCrossentropy()\n",
    "    optimizer = keras.optimizers.Adam(\n",
    "        learning_rate=0.01\n",
    "    )\n",
    "\n",
    "    \n",
    "    model.compile(optimizer=optimizer, loss=loss_fn, metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    fit_model = model.fit(train_X, train_y, epochs=50, batch_size=32, validation_split=0.1, class_weight = class_weight_dict, callbacks=[early_stopping])\n",
    "    plot_model_performance(fit_model, 'bin_cross_entropy','accuracy')\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    test_loss, test_acc = model.evaluate(test_X, test_y)\n",
    "    print(f'Test accuracy: {test_acc}')\n",
    "\n",
    "    # Make predictions on new data\n",
    "    predictions = model.predict(test_X)\n",
    "    for i in range(len(predictions)):\n",
    "        predictions[i] = 1 if predictions[i] >= 0.5 else 0\n",
    "    print(classification_report(predictions, test_y.flatten()))\n",
    "    \n",
    "    # pred_df = pd.DataFrame()\n",
    "    # pred_df['prediction'] = predictions\n",
    "    # pred_df['label'] = test_y\n",
    "    # confusion_matrix_pandas(pred_df)\n",
    "    cm = confusion_matrix(test_y, predictions)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Predicted 0', 'Predicted 1'], yticklabels=['Actual 0', 'Actual 1'])\n",
    "    plt.title(f'Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "\n",
    "train_seqs, test_seqs = nn_prepare_seqs(df)\n",
    "nn_training(train_seqs, test_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1698c017-00e4-4208-8305-518dd1746e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c12702-06f6-442b-9787-3d03ef354eec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
